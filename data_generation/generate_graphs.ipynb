{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "# create 3 random graphs with 70 nodes each\n",
    "num_graphs = 3\n",
    "num_of_distractors = 7\n",
    "graphs = []\n",
    "for i in range(num_graphs):\n",
    "    g = nx.gnp_random_graph(10, 0.1)\n",
    "    graphs.append(g)\n",
    "\n",
    "token2node = {}\n",
    "node2token = {}\n",
    "ix = 0\n",
    "for i,g in enumerate(graphs):\n",
    "    for node in g.nodes:\n",
    "        token2node[ix] = (i, node)\n",
    "        node2token[(i, node)] = ix\n",
    "        ix += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_data(graphs):\n",
    "    # pick random graph and two random nodes\n",
    "    g_idx = random.choice(list(range(len(graphs))))\n",
    "    g = graphs[g_idx]\n",
    "    node1 = random.choice(list(g.nodes))\n",
    "    node2 = random.choice(list(g.nodes))\n",
    "\n",
    "    # get shortest path between two nodes and a first node after node1\n",
    "    shortest_path = nx.shortest_path(g, node1, node2)\n",
    "    first_node_after_node1 = shortest_path[1]\n",
    "    distractors = []\n",
    "    for i in range(num_of_distractors):\n",
    "        # get index of a random graph different from g_idx\n",
    "        g_idx2 = random.choice(list(range(len(graphs))))\n",
    "        while g_idx == g_idx2:\n",
    "            g_idx2 = random.choice(list(range(len(graphs))))\n",
    "        g2 = graphs[g_idx2]\n",
    "        distractor = random.choice(list(g2.nodes))\n",
    "        distractors.append((g_idx2, distractor))\n",
    "    return  {'start_node': (g_idx, node1), \n",
    "             'end_node': (g_idx, node2),\n",
    "             'target_node': (g_idx, first_node_after_node1),\n",
    "             'distractors': distractors}\n",
    "\n",
    "def get_example(item):\n",
    "    start_token = node2token[item['start_node']]\n",
    "    end_token = node2token[item['end_node']]\n",
    "    target_token = node2token[item['target_node']]\n",
    "    distractors_tokens = [node2token[distractor] for distractor in item['distractors']]\n",
    "    input_tokens = [start_token] + distractors_tokens\n",
    "    #random.shuffle(input_tokens)\n",
    "    input_tokens = input_tokens + [end_token]\n",
    "    return {'input':input_tokens, 'target':target_token}\n",
    "\n",
    "\n",
    "def get_sample(graphs): \n",
    "    item = get_data(graphs)\n",
    "    example = get_example(item)\n",
    "    return example\n",
    "\n",
    "num_train_samples = 100000\n",
    "num_test_samples = 5000\n",
    "train_data = []\n",
    "while len(train_data)<num_train_samples:\n",
    "    #print(len(train_data))\n",
    "    try:\n",
    "        sample = get_sample(graphs)\n",
    "        train_data.append(sample)\n",
    "    except:\n",
    "        continue\n",
    "test_data = []\n",
    "while len(test_data)<num_test_samples:\n",
    "    try:\n",
    "        sample = get_sample(graphs)\n",
    "        test_data.append(sample)\n",
    "    except:\n",
    "        continue\n",
    "data = {'train': train_data, 'test': test_data,'vocab': list(token2node.keys())}\n",
    "# save to pickle\n",
    "import pickle\n",
    "with open('data_graphs.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
